---
- hosts: all
  become: yes
  vars_files:
    - "../../../LaunchZones/K8s/global-config.vars"
  tasks:
    # - name: Pre-Launch Task ... Package already deployed?
    #   shell: |
    #     kubectl get nodes --no-headers | awk '{print $2}' | grep -q 'Ready'
    #   register: basecluster_exists
    #   ignore_errors: yes
    #   args:
    #     executable: /bin/bash
    # - name: Pre-Launch Task ... Fail or Pass.
    #   fail:
    #     msg: "A cluster appears to be deployed already."
    #   when: basecluster_exists.rc != 0 or basecluster_exists.stdout == ""
    - name: Pre-Launch Task ... Install required tools
      apt:
        name:
          - ca-certificates
          - curl
          - gnupg
        state: present
        update_cache: yes

    - name: Pre-Launch Task ... Disable Swap File
      shell: swapoff -a

    - name: Pre-Launch Task ... Check if /etc/fstab file exists
      stat:
        path: /etc/fstab
      register: fstab_file

    - name: Pre-Launch Task ... Remove Swap file from /etc/fstab
      replace:
        path: /etc/fstab
        regexp: ".*swap.*"
        replace: ""
      when: fstab_file.stat.exists

    - name: Pre-Launch Task ... Create /etc/modules-load.d/k8s.conf for all worker nodes
      copy:
        content: |
          overlay
          br_netfilter
        dest: /etc/modules-load.d/k8s.conf

    - name: Pre-Launch Task ... Load the modules
      shell: sudo modprobe overlay && sudo modprobe br_netfilter
    - name: Pre-Launch Task ... Load the modules
      modprobe:
        name: "{{ item }}"
      with_items:
        - overlay
        - br_netfilter
    - name: Pre-Launch Task ... Configure kernel parameters for all nodes
      sysctl:
        name: "{{ item.key }}"
        value: "{{ item.value }}"
        sysctl_set: yes
        state: present
      with_items:
        - { key: "net.bridge.bridge-nf-call-iptables", value: "1" }
        - { key: "net.bridge.bridge-nf-call-ip6tables", value: "1" }
        - { key: "net.ipv4.ip_forward", value: "1" }

    - name: Pre-Launch Task ... Apply the changes
      shell: sudo sysctl --system

    - name: Pre-Launch Task ... Set hostname for masters
      hostname:
        name: "k8-master-{{ basecluster_start_index + groups['masters'].index(inventory_hostname) }}"
      when: "'masters' in group_names"

    - name: Pre-Launch Task ... Set hostname for workers
      hostname:
        name: "k8-worker-{{ basecluster_start_index + groups['workers'].index(inventory_hostname) }}"
      when: "'workers' in group_names"

    - name: Pre-Launch Task ... Backup /etc/hosts file (Incase we are updating, or there are existing entries.)
      shell: mv /etc/hosts /etc/hosts.bak
      ignore_errors: true

    - name: Pre-Launch Task ... Add initial entries to /etc/hosts
      copy:
        content: |
          127.0.0.1 localhost
          127.0.1.1 localhost

          # The following lines are desirable for IPv6 capable hosts
          ::1     ip6-localhost ip6-loopback
          fe00::0 ip6-localnet
          ff00::0 ip6-mcastprefix
          ff02::1 ip6-allnodes
          ff02::2 ip6-allrouters

          # Custom
        dest: /etc/hosts

    - name: Pre-Launch Task ... Update 127.0.1.1 entry in /etc/hosts
      replace:
        path: /etc/hosts
        regexp: ".*127.0.1.1.*"
        replace: "127.0.1.1 {{ ansible_hostname }}"

    - name: Pre-Launch Task ... Add entries to /etc/hosts for all hosts
      lineinfile:
        path: /etc/hosts
        line: "{{ hostvars[item]['inventory_hostname'] }} {{ hostvars[item]['ansible_hostname'] }}"
        create: yes
      loop: "{{ groups['all'] }}"
      loop_control:
        loop_var: item

    - name: Pre-Launch Task ... Install stuff
      shell: |
        apt-get update
        install -m 0755 -d /etc/apt/keyrings
        curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --yes --dearmor -o /etc/apt/keyrings/docker.gpg
        chmod a+r /etc/apt/keyrings/docker.gpg
        echo "deb [arch="$(dpkg --print-architecture)" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu "$(. /etc/os-release && echo "$VERSION_CODENAME")" stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
        apt-get update
        apt update && apt install -y containerd.io
        containerd config default | tee /etc/containerd/config.toml >/dev/null 2>&1
        sed -i 's/SystemdCgroup \= false/SystemdCgroup \= true/g' /etc/containerd/config.toml
        systemctl restart containerd && systemctl enable containerd
        apt update && apt install -y apt-transport-https ca-certificates curl gpg

    - name: Pre-Launch Task ... Install Kubernetes GPG key
      shell: |
        curl -fsSL {{ basecluster_k8s_release_key_url }} | sudo gpg --yes --dearmor -o {{ basecluster_k8s_apt_keyring_path }}
      args:
        executable: /bin/bash

    - name: Add Kubernetes repository
      apt_repository:
        repo: deb [signed-by={{ basecluster_k8s_apt_keyring_path }}] {{ basecluster_k8s_signed_by_url }} /
        state: present
        filename: kubernetes.list

    - name: Pre-Launch Task ... Install and mark hold
      shell: sudo apt update && sudo apt install -y kubelet kubeadm kubectl && sudo apt-mark hold kubelet kubeadm kubectl

# Ansible playbook to initialize the master node
- hosts: masters
  become: yes # Run as root
  vars_files:
    - "../../../LaunchZones/K8s/global-config.vars"
  tasks:
    - name: Pre-Launch Task ... Install helm
      shell: snap install helm --classic
    - name: Pre-Launch Task ... Check if the master node is already initialized
      stat:
        path: /etc/kubernetes/admin.conf
      register: kubeadm_init
    - name: Initialize the master node
      command: kubeadm init --pod-network-cidr={{ basecluster_network_cidr }}
      when: kubeadm_init.stat.exists == false # Only run if the master node is not already initialized
    - name: Create .kube directory
      file:
        path: /home/{{ become_user_setting }}/.kube
        state: directory
        owner: "{{ become_user_setting }}"
        group: "{{ become_user_setting }}"
        mode: 0744
      when: kubeadm_init.stat.exists == false # Only run if the master node is not already initialized
    - name: Post-Launch Task ... Copy the kube config file
      copy:
        src: /etc/kubernetes/admin.conf
        dest: /home/{{ become_user_setting }}/.kube/config
        remote_src: yes
        owner: "{{ become_user_setting }}"
        group: "{{ become_user_setting }}"
        mode: 0644
      when: kubeadm_init.stat.exists == false # Only run if the master node is not already initialized
    - name: Post-Launch Task ... Add Calico Repo
      kubernetes.core.helm_repository:
        name: projectcalico
        repo_url: "{{ basecluster_calico_helm_chart_url }}"
      become_user: "{{ become_user_setting }}"
    - name: Post-Launch Task ... Install Calico
      kubernetes.core.helm:
        name: calico
        namespace: "{{ basecluster_calico_namespace }}"
        chart_ref: "{{ basecluster_calico_chart_ref }}"
        create_namespace: true
        wait: true
      become_user: "{{ become_user_setting }}"
    - name: Post-Launch Task ... Get the token for joining the worker nodes
      become: yes
      become_user: "{{ become_user_setting }}"
      shell: kubeadm token create  --print-join-command
      register: kubernetes_join_command
      when: kubeadm_init.stat.exists == false # Only run if the master node is not already initialized
    - name: Post-Launch Task ... Display registered output
      debug:
        var: kubernetes_join_command.stdout_lines
      when: kubeadm_init.stat.exists == false # Only run if the master node is not already initialized
    - name: Post-Launch Task ... Create dummy host to store variable for node config
      add_host:
        name: "DUMMY_HOST"
        JOIN_COMMAND: "{{ kubernetes_join_command.stdout_lines[0] }}"
      when: kubeadm_init.stat.exists == false # Only run if the master node is not already initialized
    - name: Post-Launch Task ... Change KubeConfig permissions
      shell: chmod go-r /home/{{ become_user_setting }}/.kube/config

# Ansible playbook to join the worker nodes to the cluster
- hosts: workers
  become: yes # Run as root
  tasks:
    - name: Post-Launch Task ... Check if the worker node is already joined
      stat:
        path: /etc/kubernetes/kubelet.conf
      register: kubeadm_already_joined
    # - name: Post-Launch Task ... Debug Information
    #   debug:
    #     var: hostvars['DUMMY_HOST']
    - name: Post-Launch Task ... Join the worker nodes to the cluster
      command: "{{ hostvars['DUMMY_HOST']['JOIN_COMMAND'] }}"
      become: yes
      when: kubeadm_already_joined.stat.exists == false # Only run if the worker node is not already joined
